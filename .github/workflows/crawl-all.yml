name: All Crawlers

on:
  # Manual trigger
  workflow_dispatch:

  # Scheduled run (daily at 2 AM UTC)
  schedule:
    - cron: '0 2 * * *'

jobs:
  crawl-all:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          playwright install chromium
          playwright install-deps chromium

      - name: Run All Crawlers
        env:
          MONGO_URI: ${{ secrets.MONGO_URI }}
          MONGO_DB: ${{ secrets.MONGO_DB }}
          FACEBOOK_COOKIE: ${{ secrets.FACEBOOK_COOKIE }}
          FACEBOOK_KEYWORDS: ${{ secrets.FACEBOOK_KEYWORDS }}
          MAX_SCROLLS: 5
          LOG_LEVEL: INFO
        run: |
          python -m src.main all

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: all-crawlers-logs-${{ github.run_number }}
          path: logs/
          retention-days: 14

      - name: Upload data
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: all-crawlers-data-${{ github.run_number }}
          path: data/
          retention-days: 14